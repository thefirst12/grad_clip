# -*- coding: utf-8 -*-
"""Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Dy52s0y6D-lvNVC291Cq4eU-XLzpIf20
"""

import numpy as np

def clip_gradients(gradients, max_norm):

    grad_norm = np.linalg.norm(gradients)

    if grad_norm > max_norm:
        scaling_factor = max_norm / grad_norm
        gradients = gradients * scaling_factor

    return gradients

def clip_gradients_by_value(gradients, threshold):

    gradients = np.clip(gradients, -threshold, threshold)
    return gradients

gradients = np.array([1.2, 101, 3.5, -2.4, 0.00001])

# Применение клиппинга по норме
max_norm = 5.0
clipped_gradients = clip_gradients(gradients, max_norm)
print("Отклиппированные градиенты по норме:", clipped_gradients)

# Применение клиппинга по значению
threshold = 2.0
clipped_gradients_by_value = clip_gradients_by_value(gradients, threshold)
print("Отклиппированные градиенты по значению:", clipped_gradients_by_value)

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import mean_squared_error

np.random.seed(42)
X = np.random.rand(1000, 1)
y = 5 * X + 3 + np.random.normal(0, 0.5, (1000, 1))

def stochastic_gradient_descent(X, y, learning_rate=0.1, epochs=100, batch_size=1):
    m = len(y)
    theta = np.zeros((X.shape[1] + 1, 1))
    X_b = np.c_[np.ones((m, 1)), X]

    for epoch in range(epochs):
        for i in range(0, m, batch_size):
            random_index = np.random.randint(m)
            xi = X_b[random_index:random_index+1]
            yi = y[random_index:random_index+1]

            gradients = 2 * xi.T.dot(xi.dot(theta) - yi)
            theta -= learning_rate * gradients

    return theta

theta_no_clip = stochastic_gradient_descent(X, y, learning_rate=0.1, epochs=100, batch_size=1)
print(f"Параметры без клиппинга: {theta_no_clip.ravel()}")

y_pred_no_clip = np.c_[np.ones((X.shape[0], 1)), X].dot(theta_no_clip)
mse_no_clip = mean_squared_error(y, y_pred_no_clip)
print(f"Среднеквадратичная ошибка (MSE) без клиппинга: {mse_no_clip}")

plt.scatter(X, y, color='blue', label='Исходные данные')
plt.plot(X, y_pred_no_clip, color='red', label='Линия регрессии (без клиппинга)')
plt.legend()
plt.xlabel('Признак')
plt.ylabel('Целевая переменная')
plt.title('Линейная регрессия (без градиентного клиппинга)')
plt.show()

def clip_gradients(gradients, max_norm):
    grad_norm = np.linalg.norm(gradients)
    if grad_norm > max_norm:
        scaling_factor = max_norm / grad_norm
        gradients = gradients * scaling_factor
    return gradients

def stochastic_gradient_descent_with_clipping(X, y, learning_rate=0.1, epochs=100, batch_size=1, max_grad_norm=1.0):
    m = len(y)
    theta = np.zeros((X.shape[1] + 1, 1))
    X_b = np.c_[np.ones((m, 1)), X]

    for epoch in range(epochs):
        for i in range(0, m, batch_size):
            random_index = np.random.randint(m)
            xi = X_b[random_index:random_index+1]
            yi = y[random_index:random_index+1]

            gradients = 2 * xi.T.dot(xi.dot(theta) - yi)
            gradients = clip_gradients(gradients, max_grad_norm)
            theta -= learning_rate * gradients

    return theta

theta_with_clip = stochastic_gradient_descent_with_clipping(X, y, learning_rate=0.1, epochs=100, batch_size=1, max_grad_norm=1.0)
print(f"Параметры с клиппингом: {theta_with_clip.ravel()}")

y_pred_with_clip = np.c_[np.ones((X.shape[0], 1)), X].dot(theta_with_clip)
mse_with_clip = mean_squared_error(y, y_pred_with_clip)
print(f"Среднеквадратичная ошибка (MSE) с клиппингом: {mse_with_clip}")

plt.scatter(X, y, color='blue', label='Исходные данные')
plt.plot(X, y_pred_with_clip, color='black', label='Линия регрессии (с клиппингом)')
plt.legend()
plt.xlabel('Признак')
plt.ylabel('Целевая переменная')
plt.title('Линейная регрессия (с градиентным клиппингом)')
plt.show()

def clip_gradients(gradients, max_norm):
    grad_norm = np.linalg.norm(gradients)
    if grad_norm > max_norm:
        scaling_factor = max_norm / grad_norm
        gradients = gradients * scaling_factor
    return gradients

def stochastic_gradient_descent_with_clipping(X, y, learning_rate=0.1, epochs=100, batch_size=1, max_grad_norm=1.0):
    m = len(y)
    theta = np.zeros((X.shape[1] + 1, 1))
    X_b = np.c_[np.ones((m, 1)), X]

    for epoch in range(epochs):
        for i in range(0, m, batch_size):
            random_index = np.random.randint(m)
            xi = X_b[random_index:random_index+1]
            yi = y[random_index:random_index+1]

            gradients = 2 * xi.T.dot(xi.dot(theta) - yi)
            gradients = clip_gradients_by_value(gradients, threshold)
            theta -= learning_rate * gradients

    return theta

theta_with_clip = stochastic_gradient_descent_with_clipping(X, y, learning_rate=0.1, epochs=100, batch_size=1, max_grad_norm=1.0)
print(f"Параметры с клиппингом: {theta_with_clip.ravel()}")

y_pred_with_clip = np.c_[np.ones((X.shape[0], 1)), X].dot(theta_with_clip)
mse_with_clip = mean_squared_error(y, y_pred_with_clip)
print(f"Среднеквадратичная ошибка (MSE) с клиппингом: {mse_with_clip}")

plt.scatter(X, y, color='blue', label='Исходные данные')
plt.plot(X, y_pred_with_clip, color='green', label='Линия регрессии (с клиппингом)')
plt.legend()
plt.xlabel('Признак')
plt.ylabel('Целевая переменная')
plt.title('Линейная регрессия (с градиентным клиппингом)')
plt.show()

import torch
import torchvision
import torchvision.transforms as transforms
from torch import nn, optim
from torchvision import datasets, models
import matplotlib.pyplot as plt
import time
import os

# Настройки
batch_size = 32
num_epochs = 10
learning_rate = 0.001
max_grad_norm = 1.0  # Максимальный градиентный норм для клиппинга

# 1. Подготовка данных
# Для ImageNet используется большой датасет, поэтому для примера будем использовать датасет ImageNet в небольшой подмножество.
# В реальной задаче вы можете использовать собственную копию датасета, или загрузить через TorchHub.

# Трансформации для обучения и валидации
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Загружаем данные
train_data = datasets.ImageFolder(root='path_to_imagenet_train', transform=transform)
val_data = datasets.ImageFolder(root='path_to_imagenet_val', transform=transform)

train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)
val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=4)

# 2. Создание модели
# Используем предобученную модель ResNet18
model = models.resnet18(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, 1000)  # 1000 классов в ImageNet

# Перемещаем модель на GPU, если доступно
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = model.to(device)

# 3. Определение потерь и оптимизатора
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# 4. Функция для тренировки модели
def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs, max_grad_norm):
    best_model_wts = model.state_dict()
    best_acc = 0.0

    for epoch in range(num_epochs):
        print(f'Epoch {epoch+1}/{num_epochs}')
        print('-' * 10)

        # Каждую эпоху тренируем модель
        model.train()
        running_loss = 0.0
        corrects = 0
        total = 0

        for inputs, labels in train_loader:
            inputs = inputs.to(device)
            labels = labels.to(device)

            optimizer.zero_grad()

            # Прямой проход
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            # Обратный проход
            loss.backward()

            # Применение градиентного клиппинга
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)

            optimizer.step()

            # Статистика
            running_loss += loss.item() * inputs.size(0)
            _, preds = torch.max(outputs, 1)
            corrects += torch.sum(preds == labels.data)
            total += labels.size(0)

        epoch_loss = running_loss / len(train_loader.dataset)
        epoch_acc = corrects.double() / total

        print(f'Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

        # Оценка на валидации
        model.eval()
        val_loss = 0.0
        corrects = 0
        total = 0

        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs = inputs.to(device)
                labels = labels.to(device)

                outputs = model(inputs)
                loss = criterion(outputs, labels)

                val_loss += loss.item() * inputs.size(0)
                _, preds = torch.max(outputs, 1)
                corrects += torch.sum(preds == labels.data)
                total += labels.size(0)

        val_loss = val_loss / len(val_loader.dataset)
        val_acc = corrects.double() / total

        print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')

        # Сохраняем лучшую модель
        if val_acc > best_acc:
            best_acc = val_acc
            best_model_wts = model.state_dict()

    print('Training complete.')
    print(f'Best val Acc: {best_acc:.4f}')

    # Загружаем лучшие веса
    model.load_state_dict(best_model_wts)
    return model

# 5. Обучаем модель
model = train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs, max_grad_norm)

# 6. Выводим результаты
# Можно вывести пример предсказаний
model.eval()
inputs, labels = next(iter(val_loader))
inputs, labels = inputs.to(device), labels.to(device)
outputs = model(inputs)
_, preds = torch.max(outputs, 1)

# Печатаем несколько примеров
for i in range(5):
    print(f'Predicted: {preds[i].item()}, True: {labels[i].item()}')

# Вывод графиков
# Вы можете добавить графики потерь и точности на обучении и валидации для дальнейшего анализа

import torch
import torch.nn as nn
import torch.nn.functional as F

# Определим базовый блок Residual
class BasicBlock(nn.Module):
    def __init__(self, in_channels, out_channels, stride=1):
        super(BasicBlock, self).__init__()

        # Слой свертки, нормализация и активация
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(out_channels)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(out_channels)

        # Остаточная связь (shortcut)
        self.shortcut = nn.Sequential()

        # Если входные и выходные каналы не совпадают, добавим слои для выравнивания
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(out_channels)
            )

    def forward(self, x):
        out = F.relu(self.bn1(self.conv1(x)))  # Проход через 1-ю свертку
        out = self.bn2(self.conv2(out))        # Проход через 2-ю свертку
        out += self.shortcut(x)                # Остаточная связь
        out = F.relu(out)                      # Активация после остаточной связи
        return out


# Теперь определим саму модель ResNet-18
class ResNet18(nn.Module):
    def __init__(self, num_classes=1000):
        super(ResNet18, self).__init__()

        # Начальная свертка
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.relu = nn.ReLU(inplace=True)
        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        # Слои, состоящие из блоков residual
        self.layer1 = self._make_layer(64, 64, 2, stride=1)
        self.layer2 = self._make_layer(64, 128, 2, stride=2)
        self.layer3 = self._make_layer(128, 256, 2, stride=2)
        self.layer4 = self._make_layer(256, 512, 2, stride=2)

        # Полносвязный слой для классификации
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))  # Адаптивное среднее объединение
        self.fc = nn.Linear(512, num_classes)  # Для ImageNet это 1000 классов

    def _make_layer(self, in_channels, out_channels, blocks, stride):
        layers = []
        layers.append(BasicBlock(in_channels, out_channels, stride))

        # Добавляем оставшиеся блоки
        for _ in range(1, blocks):
            layers.append(BasicBlock(out_channels, out_channels))

        return nn.Sequential(*layers)

    def forward(self, x):
        x = self.relu(self.bn1(self.conv1(x)))  # Применяем первую свертку и активацию
        x = self.maxpool(x)                    # Применяем maxpooling

        x = self.layer1(x)  # Применяем слой 1
        x = self.layer2(x)  # Применяем слой 2
        x = self.layer3(x)  # Применяем слой 3
        x = self.layer4(x)  # Применяем слой 4

        x = self.avgpool(x)  # Адаптивное среднее объединение
        x = torch.flatten(x, 1)  # Преобразуем в вектор
        x = self.fc(x)  # Прогоняем через полносвязный слой
        return x

# Проверим работу модели
model = ResNet18(num_classes=1000)
print(model)

import kagglehub

# Download latest version
path = kagglehub.dataset_download("ambityga/imagenet100")

print("Path to dataset files:", path)

data = datasets.ImageFolder(root="/root/.cache/kagglehub/datasets/ambityga/imagenet100/versions/8", transform=transform)

data

print("Path to dataset files:", path)
!ls {path}

import os
import shutil
import random
from pathlib import Path
from sklearn.model_selection import train_test_split

# Путь к скачанному датасету
dataset_path = Path(path)  # Здесь path - это путь, который был выведен ранее

# Проверим структуру
print(f"Dataset path: {dataset_path}")
!ls {dataset_path}

# Проверим, как устроены папки в датасете
train_dir = dataset_path / "train.X1"  # Убедитесь, что здесь именно "train"
print(f"Train folder contents: {os.listdir(train_dir)}")

# Если нужно разделить на train и validation:
# 1. Перебираем все классы (папки)
class_folders = os.listdir(train_dir)

# 2. Создаем директорию для validation
valid_dir = dataset_path / "val.X"
valid_dir.mkdir(parents=True, exist_ok=True)

# Разделяем данные для каждого класса
for class_folder in class_folders:
    class_path = train_dir / class_folder
    files = os.listdir(class_path)

    # Разделим файлы на train и validation
    train_files, valid_files = train_test_split(files, test_size=0.2, random_state=42)

    # Создаем папки для validation, если их нет
    valid_class_folder = valid_dir / class_folder
    valid_class_folder.mkdir(parents=True, exist_ok=True)

    # Перемещаем файлы в папку validation
    for file in valid_files:
        shutil.move(str(class_path / file), str(valid_class_folder / file))

# Теперь у вас есть папки "train" и "valid", которые можно передать в ImageFolder

import os
import torch
import torchvision
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from torchvision import datasets, models
from tqdm import tqdm
import numpy as np
from sklearn.metrics import accuracy_score

# Проверим, доступен ли GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 1. Подготовка данных
# Замените путь на актуальный путь к вашему датасету на Kaggle
train_dir = "path_to_imagenet_train"
val_dir = "path_to_imagenet_val"

# Трансформации для обучения и валидации
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

# Загружаем данные
train_data = datasets.ImageFolder(root=dataset_path / 'train.X1', transform=transform)
val_data = datasets.ImageFolder(root=dataset_path / 'val.X', transform=transform)

train_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4)
val_loader = DataLoader(val_data, batch_size=32, shuffle=False, num_workers=4)

# 2. Создание модели (ResNet18)
model = models.resnet18(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, 1000)  # ImageNet имеет 1000 классов

model = model.to(device)

# 3. Определение функции потерь и оптимизатора
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

# 4. Функция для тренировки модели
def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, max_grad_norm=1.0):
    train_loss = []
    val_loss = []
    train_acc = []
    val_acc = []

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        corrects = 0
        total = 0

        for inputs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs}"):
            inputs, labels = inputs.to(device), labels.to(device)

            optimizer.zero_grad()

            # Прямой проход
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            # Обратный проход
            loss.backward()

            # Градиентный клиппинг
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)

            optimizer.step()

            # Статистика
            running_loss += loss.item() * inputs.size(0)
            _, preds = torch.max(outputs, 1)
            corrects += torch.sum(preds == labels.data)
            total += labels.size(0)

        epoch_loss = running_loss / len(train_loader.dataset)
        epoch_acc = corrects.double() / total
        train_loss.append(epoch_loss)
        train_acc.append(epoch_acc)

        # Оценка на валидации
        model.eval()
        val_running_loss = 0.0
        val_corrects = 0
        val_total = 0

        with torch.no_grad():
            for inputs, labels in tqdm(val_loader, desc="Validation"):
                inputs, labels = inputs.to(device), labels.to(device)

                outputs = model(inputs)
                loss = criterion(outputs, labels)

                val_running_loss += loss.item() * inputs.size(0)
                _, preds = torch.max(outputs, 1)
                val_corrects += torch.sum(preds == labels.data)
                val_total += labels.size(0)

        val_loss_value = val_running_loss / len(val_loader.dataset)
        val_acc_value = val_corrects.double() / val_total
        val_loss.append(val_loss_value)
        val_acc.append(val_acc_value)

        print(f"Epoch {epoch+1}/{num_epochs} - Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}")
        print(f"Epoch {epoch+1}/{num_epochs} - Val Loss: {val_loss_value:.4f}, Val Acc: {val_acc_value:.4f}")

    return train_loss, val_loss, train_acc, val_acc

# 5. Обучаем модель
train_loss, val_loss, train_acc, val_acc = train_model(
    model, train_loader, val_loader, criterion, optimizer, num_epochs=10, max_grad_norm=1.0
)

# 6. Выводим результаты

# Графики потерь
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(train_loss, label="Train Loss")
plt.plot(val_loss, label="Val Loss")
plt.title("Loss over epochs")
plt.legend()

# Графики точности
plt.subplot(1, 2, 2)
plt.plot(train_acc, label="Train Accuracy")
plt.plot(val_acc, label="Val Accuracy")
plt.title("Accuracy over epochs")
plt.legend()

plt.show()